{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17712,
     "status": "ok",
     "timestamp": 1762289274277,
     "user": {
      "displayName": "D R",
      "userId": "04125091294042394805"
     },
     "user_tz": -180
    },
    "id": "LNNlyd4Mn_gw",
    "outputId": "e2335088-e4a6-444f-828a-0e8a8553cb2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting river\n",
      "  Downloading river-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from river) (2.0.2)\n",
      "Collecting pandas<3.0.0,>=2.2.3 (from river)\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy<2.0.0,>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from river) (1.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.3->river) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.3->river) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.2.3->river) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.3->river) (1.17.0)\n",
      "Downloading river-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas, river\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
      "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-2.3.3 river-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "executionInfo": {
     "elapsed": 17107,
     "status": "ok",
     "timestamp": 1762290242016,
     "user": {
      "displayName": "D R",
      "userId": "04125091294042394805"
     },
     "user_tz": -180
    },
    "id": "qkKHd_65rhKY",
    "outputId": "eaa686ff-7d7f-4567-e295-663311131d32"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'river'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mriver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     datasets,\n\u001b[32m      4\u001b[39m     ensemble,\n\u001b[32m      5\u001b[39m     metrics,\n\u001b[32m      6\u001b[39m     tree\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# --- 1. Настройка эксперимента ---\u001b[39;00m\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Создаем синтетический поток данных SEA.\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# variant=1 означает, что в середине потока произойдет резкое изменение\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# в правилах классификации (внезапный дрейф).\u001b[39;00m\n\u001b[32m     14\u001b[39m drift_point = \u001b[32m2500\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'river'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from river import (\n",
    "    datasets,\n",
    "    ensemble,\n",
    "    metrics,\n",
    "    tree\n",
    ")\n",
    "\n",
    "# --- 1. Настройка эксперимента ---\n",
    "\n",
    "# Создаем синтетический поток данных SEA.\n",
    "# variant=1 означает, что в середине потока произойдет резкое изменение\n",
    "# в правилах классификации (внезапный дрейф).\n",
    "drift_point = 2500\n",
    "dataset = datasets.synth.SEA(seed=42, variant=1).take(5000)\n",
    "\n",
    "# Список моделей, которые мы будем сравнивать\n",
    "models = {\n",
    "    \"Одиночное дерево (HT)\": tree.HoeffdingTreeClassifier(),\n",
    "\n",
    "    \"Обычный Бэггинг (Bagging)\": ensemble.BaggingClassifier(\n",
    "        model=tree.HoeffdingTreeClassifier(),\n",
    "        n_models=10,\n",
    "        seed=42\n",
    "    ),\n",
    "\n",
    "    # ИСПРАВЛЕНО: Используем 'LeveragingBaggingClassifier'.\n",
    "    # Это мощный ансамбль, специально разработанный для работы с дрейфом.\n",
    "    # Он сочетает бэггинг с механизмом ADWIN для повышения производительности.\n",
    "    \"Адаптивный Бэггинг (Leveraging Bagging)\": ensemble.LeveragingBaggingClassifier(\n",
    "        model=tree.HoeffdingTreeClassifier(),\n",
    "        n_models=10,\n",
    "        seed=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Словарь для хранения метрик точности для каждой модели\n",
    "metrics_dict = {name: metrics.Accuracy() for name in models.keys()}\n",
    "\n",
    "# Словарь для хранения истории производительности для построения графика\n",
    "performance_history = {name: [] for name in models.keys()}\n",
    "plot_every_n_steps = 100\n",
    "\n",
    "# --- 2. Цикл онлайн-обучения ---\n",
    "\n",
    "print(\"Начинаем обработку потока данных...\")\n",
    "\n",
    "for i, (x, y) in enumerate(dataset):\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        y_pred = model.predict_one(x)\n",
    "\n",
    "        if y_pred is not None:\n",
    "            metrics_dict[model_name].update(y, y_pred)\n",
    "\n",
    "        model.learn_one(x, y)\n",
    "\n",
    "    if (i + 1) % plot_every_n_steps == 0:\n",
    "        for model_name in models.keys():\n",
    "            accuracy = metrics_dict[model_name].get()\n",
    "            performance_history[model_name].append(accuracy)\n",
    "\n",
    "print(\"Обработка завершена.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 3. Вывод результатов ---\n",
    "\n",
    "print(\"Итоговая точность:\")\n",
    "for model_name, metric in metrics_dict.items():\n",
    "    print(f\"  - {model_name}: {metric.get():.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "x_axis = range(plot_every_n_steps, 5000 + 1, plot_every_n_steps)\n",
    "\n",
    "for model_name, history in performance_history.items():\n",
    "    ax.plot(x_axis, history, label=model_name, marker='o', markersize=3, alpha=0.8)\n",
    "\n",
    "ax.axvline(drift_point, color='red', linestyle='--', label=f'Дрейф концепта (на {drift_point})')\n",
    "\n",
    "ax.set_title(\"Сравнение производительности онлайн-ансамблей в условиях дрейфа концепта\")\n",
    "ax.set_xlabel(\"Количество обработанных примеров\")\n",
    "ax.set_ylabel(\"Точность (Prequential Accuracy)\")\n",
    "ax.legend()\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "ax.set_ylim(0.5, 1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bbDfBjsscvI"
   },
   "source": [
    "Конечно! Вот подробное объяснение кода, специально отформатированное для текстовой ячейки в Jupyter Notebook. Вы можете просто скопировать и вставить этот текст в Markdown-ячейку над ячейкой с кодом.\n",
    "\n",
    "---\n",
    "\n",
    "# Анализ производительности онлайн-ансамблей в условиях дрейфа концепта\n",
    "\n",
    "## 1. Цель эксперимента\n",
    "\n",
    "Данный код представляет собой симуляцию, цель которой — наглядно продемонстрировать преимущества **адаптивных онлайн-ансамблей** по сравнению с одиночными моделями и простыми ансамблями при работе с нестационарными данными.\n",
    "\n",
    "Ключевая проблема, которую мы исследуем, — это **дрейф концепта** (*concept drift*). Так называют ситуацию, когда статистические свойства данных или зависимости между ними со временем меняются. Модель, обученная на \"старых\" данных, начинает сильно ошибаться на \"новых\". Наша задача — сравнить, насколько быстро и эффективно разные модели могут адаптироваться к таким изменениям.\n",
    "\n",
    "## 2. Дизайн эксперимента\n",
    "\n",
    "### 2.1. Данные\n",
    "\n",
    "Мы используем синтетический генератор потока данных `river.datasets.synth.SEA`. Его главное преимущество — возможность **контролируемого эксперимента**. Мы точно знаем, в какой момент времени (`drift_point = 2500`) в потоке данных произойдет резкое изменение правил, по которым метки присваиваются объектам. Это позволяет нам точно измерить реакцию моделей на дрейф.\n",
    "\n",
    "### 2.2. Участники сравнения\n",
    "\n",
    "Мы сравниваем три модели, представляющие три разных уровня сложности:\n",
    "\n",
    "1.  **`tree.HoeffdingTreeClassifier` (Одиночное дерево)**\n",
    "    *   **Роль:** Контрольная группа (baseline). Это эффективная базовая модель для потоковой классификации, но у нее нет специальных механизмов для борьбы с дрейфом. Мы ожидаем, что она будет медленнее всех восстанавливаться после изменений.\n",
    "\n",
    "2.  **`ensemble.BaggingClassifier` (Обычный Бэггинг)**\n",
    "    *   **Роль:** Простой ансамбль. Эта модель состоит из 10 деревьев Хоффдинга. Разнообразие моделей достигается за счет того, что каждое дерево обучается на своей случайной подвыборке данных (согласно распределению Пуассона). За счет усреднения предсказаний ансамбль должен быть более стабильным и точным, чем одиночная модель, но у него нет *активного* механизма адаптации к дрейфу.\n",
    "\n",
    "3.  **`ensemble.LeveragingBaggingClassifier` (Адаптивный Бэггинг)**\n",
    "    *   **Роль:** Продвинутый адаптивный ансамбль. Это усовершенствованная версия бэггинга. Она также состоит из 10 деревьев, но дополнительно использует механизм взвешивания на основе ошибок (ADWIN), чтобы повысить производительность в условиях дрейфа. Ансамбль отдает большее предпочтение тем моделям, которые лучше справляются с новыми данными, и быстрее избавляется от влияния устаревших знаний. Мы ожидаем, что эта модель покажет наилучшую скорость адаптации.\n",
    "\n",
    "### 2.3. Процесс обучения и оценки\n",
    "\n",
    "Мы симулируем **онлайн-обучение**, обрабатывая поток данных по одному объекту за раз. Для оценки качества используется протокол **Prequential-оценки** (или \"Test-then-Train\"):\n",
    "\n",
    "1.  **Тест:** Для каждого нового объекта модель сначала делает предсказание.\n",
    "2.  **Оценка:** Это предсказание сравнивается с истинной меткой, и метрика точности (Accuracy) обновляется.\n",
    "3.  **Обучение:** И только после этого модель обучается на этом объекте.\n",
    "\n",
    "Такой подход дает честную оценку способности модели работать с ранее невиданными данными.\n",
    "\n",
    "## 3. Что происходит в коде?\n",
    "\n",
    "*   **Блок 1 (Настройка):** Мы инициализируем генератор данных, создаем три наши модели и готовим структуры для сбора метрик и истории производительности.\n",
    "*   **Блок 2 (Цикл онлайн-обучения):** Главный цикл, который итерируется по 5000 объектам из потока данных. Внутри цикла каждая из трех моделей проходит шаги \"Тест -> Оценка -> Обучение\". Каждые 100 шагов мы записываем текущее значение точности для последующей визуализации.\n",
    "*   **Блок 3 (Результаты и визуализация):**\n",
    "    *   Мы выводим итоговую точность каждой модели за весь прогон.\n",
    "    *   Мы строим график, который является **главным результатом эксперимента**. На нем показано, как менялась скользящая точность каждой модели во времени. Красная пунктирная линия отмечает момент, когда в данных произошел дрейф.\n",
    "\n",
    "## 4. Что ожидать на графике?\n",
    "\n",
    "1.  **До дрейфа (до отметки 2500):** Все модели будут быстро обучаться, и их точность выйдет на высокий стабильный уровень (вероятно, выше 90%).\n",
    "2.  **В момент дрейфа (на отметке 2500):** Мы увидим **резкое падение точности у всех моделей**. Это показывает, что их знания, полученные на старых данных, больше не актуальны.\n",
    "3.  **После дрейфа (после отметки 2500):** Здесь проявится ключевое различие:\n",
    "    *   Кривая **одиночного дерева** будет восстанавливаться очень медленно.\n",
    "    *   Кривая **обычного бэггинга** будет подниматься быстрее за счет большей гибкости.\n",
    "    *   Кривая **адаптивного бэггинга (`LeveragingBaggingClassifier`)** покажет самую высокую скорость восстановления. Благодаря своему внутреннему механизму адаптации, эта модель быстрее всех \"поймет\", что правила изменились, и перестроится под новые данные.\n",
    "\n",
    "Таким образом, эксперимент наглядно демонстрирует, почему для работы с реальными, постоянно меняющимися данными, использование специализированных адаптивных ансамблей является критически важным."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNv7PsSsur2TmXQ9m4Crk0Q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
